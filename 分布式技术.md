# CAP

**cap原理**：关于数据一致性（ C：Consistency ）、服务可用性（ A：Availability ）、分区容错性（ P：Partition-tolerance ）的一个著名猜想。**一个分布式系统不可能同时满足数据一致性、服务可用性和分区容错性这三个基本需求，最多只能同时满足其中的两个**。对于分布式系统工程实践来说， CAP 理论更合适的描述是：在满足分区容错的前提下，没有算法能同时满足数据一致性和服务可用性。

# 负载均衡   

背景：为了实现系统的高可用和高性能，它所有的服务都会部署多个实例，调用方应该将请求，发向被调用服务的哪一个服务实例

根据负载均衡策略是否关心请求中携带的信息，即请求是否有状态，将负载均衡策略分为无状态的负载均衡、半状态的负载均衡和全状态的负载均衡



关键点是**公平性与正确性**，





## 策略：

**无状态负载均衡**

轮询：请求按顺序分配给多个实例，适用于请求的工作负载和实例的处理能力差异都较小的情况

权重轮询：将每一个后端实例分配一个权重，分配请求的数量和实例的权重成正比轮询，可以利用它解决实例的处理能力差异的问题，

​					它的公平性比轮询策略要好。



**半状态：**利用请求的状态信息进行路由，但是仅仅进行简单的规则处理

hash（按实例数求模）：将请求的状态信息，按一定的 Hash 算法固定分配到一个实例上

一致性hash（对固定值求模）

“其实全状态的负载均衡和数据分片是同一件事情”



# 分布式锁

锁的定义：锁是操作系统的基于原语，它是用于并发控制的，能够确保在多 CPU 、多个线程的环境中，某一个时间点上，只能有一个线程进入临界区代码，从而保证临界区中操作数据的一致性。

特性：**互斥** ：即保证不同节点、不同线程的互斥访问；

**超时机制** 即超时设置，防止死锁（避免获得锁的节点长时间执行，还未执行完，锁就释放的问题，可以在每一次成功获得锁的时候，为锁设置一个超时时间，获得锁的节点与锁服务保持心跳，锁服务每一次收到心跳，就延长锁的超时时间），分布式锁才有这个特性  ；

**公平性** 

对于在共享存储中写入数据等等，完全不能容忍分布式锁互斥语义失败的情况，不应该借助分布式锁从外部来实现，而是应该在共享存储内部来解决。比如，在数据库的实现中，隔离性就是专门来解决这个问题的。**分布式锁的设计，应该多关注高可用与性能，以及怎么提高正确性，而不是追求绝对的正确性**。





### 实现

减库存场景，解决超卖问题

最简单的实现

```
try{
  redis.setnx(key,val,expire)    //set lock_product_1001 1 nx ex 10,加失效时间是防止代码中途崩溃导致锁没有删除
  //code
  
}finally{
	redis.del(key)
}

//可能出现的问题，1执行code时系统宕机，2key过期之后执行del，导致锁失效
```



**锁失效问题**：高并发场景下线程1加锁成功，失效时间设置10S，但是code执行需要15s，在10s时所以自动删除，此时线程2加锁成功。第15s时线程1执行del(key)实际上删除的时线程2的锁

优化

```
try{
	clientId = UUID.randomUUID() 		//给每一个客户端设置一个唯一ID
  redis.setnx(key,clientId,expire)    
  //code
  
}finally{
	if(clientId == redis.get(key))	//谁加锁谁释放
	redis.del(key)					
}


```



进一步优化，**锁续命**：在后台开启一个新的线程，开一个定时任务，每隔3s（超时时间的1/3）检查锁，如果存在重新设置超时时间（10s）。如果锁不存在，直接结束线程 



更好的实现，参考redisson，两个优化

1、使用lua脚本，保证命令执行的原子性

2、使用锁续命机制，即新开一个线程，定时任务检测所是否存在，若存在重新设置expire（定时任务间隔时间<expire）



```
//使用redisson实现分布式锁
redissonLock = redisson.getlock(key)
try{
	 redissonLock.lock()  	//加锁，实现锁续命功能
  //code
  
}finally{
	redissonLock.unlock()					
}


```





### 锁丢失问题

![image-20230524224500792](static/images/image-20230524224500792.png)



当redis master向slave同步的过程中宕机了，锁信息未同步到slave中，slave成了新的master，此时新的线程可以加锁执行，导致了并发安全问题。这种问题一般可以容忍（记录日志）。也可以使用zookeeper



分布式锁类型

redis：**AP模型，高性能**，主节点写入成功即可，会导致锁丢失问题

zookeeper：**CP模型，数据一致**，与redis架构的区别是，节点必须大于三，往主节点写入key，会同步子节点，超过半数写成功，才返回成功。不会有锁丢失问题

RedLock：超过半数redis节点加锁成功才算加锁成功



### 提升并发

**分段加锁（锁粒度）**

lock_stock_id     分段成lock_stock_id_1  lock_stock_id_2   lock_stock_id_3  





**Exactly-once** 在请求的响应结果为“请求超时”的时候，我们不知道这个请求是否已经被远端的服务执行了（可能是网络原因或者服务器故障），进一步来说就是请求的消息，是否精确一次发送到远端服务的问题，即 Exactly-once。

保证 Exactly-once：**至少一次消息传递加消息幂等性**

 确保至少一次消息传递：如果调用方在课程购买的 RPC 接口返回网络层错误，比如请求超时以及网络地址不可达等，对于这样的情况，调用方就进行重试，直到响应结果为成功或业务错误等非网络层错误。

幂等：对用户发起的每一次业务（如课程购买）请求，生成一个唯一的 ID ，然后在课程购买的 RPC 请求中带上这个唯一的 ID ，在首次调用和重试的时候，这个唯一的 ID 都保持不变。接着，课程购买服务在接收到请求后，先查询当前的 ID 是否已经处理过，如果是已经处理过的请求，就直接返回结果，不重复执行购买相关的逻辑了。这里要特别注意的是，将请求处理结果写入数据库的操作，以及标记请求已处理的操作，也就是将请求唯一的 ID 写入数据库，它们都必须在同一个事务中，**让事务来保证这两个操作的原子性**。

# 雪崩

因为局部故障被正反馈循环导致不断放大，会使系统出现雪崩。

想要避免系统雪崩，要么通过快速减少系统负载，即熔断、降级、限流等快速失败和降级机制；要么通过快速增加系统的服务能力来避免雪崩的发生，即弹性扩容机制。

**对熔断、限流和降级的理解**

首先，因为熔断机制是系统稳定性保障的最后一道防线，并且它是自适应的，所以我们应该在系统全局默认启用；其次，限流是用来保障被限流服务稳定性的，所以我们建议，一般在系统的核心链路和核心服务上，默认启用限流机制；最后，降级是通过牺牲被降级的接口或者服务，来保障其他的接口和服务正常运行的，所以我们可以通过降级直接停用非核心服务，然后对于核心接口和服务，在必要的时候，可以提供一个“B 计划”。

## 熔断

粒度控制：服务实例的接口，粒度细、敏感度高

熔断机制是被动感知故障，然后再进行处理的，它需要先让过载发生，等系统出现故障后，才会介入处理，让系统恢复到正常。

这样的处理方式会让系统产生不必要的抖动，如果是处理意料之外的过载问题，我们是可以接受的。但是，在明知道服务的服务能力的情况下，依然让故障发生，然后在事后进行被动处理，这个处理思路就不够优雅了。

**熔断机制应该作为系统稳定性保障的最后一道防线**

## 限流

### 限流算法 

固定窗口：抗抖动性差，流量集中时会出现问题

滑动窗口：对固定窗口做了进一步切分，将统计周期的粒度切分得更细，一样面临抗抖动性差的问题

**漏桶**：改进抗抖动性差的问题

改进点，第一，增加了一个桶来缓存请求，在流量突增的时候，可以先缓存起来，直到超过桶的容量才触发限流；

第二，对出口的流量上限做了限制，使上游流量的抖动不会扩散到下游服务。这两个改进大大提高了系统的抗抖动能力，使漏桶有了流量整形的能力

缺点：其中流出速率是漏桶限流的防线，一般会设置得相对保守，可是这样就**无法完全利用系统的性能**，就增加了请求的排队时间。



**令牌桶**：以“恒定”的速率生产令牌，但是请求获取令牌的速率是“可变”的，桶里只要有令牌就直接发，令牌没了就触发限流

“令牌桶”算法相对于“漏桶”，虽然提高了系统的资源利用率，但是却放弃了一定的流量整形能力，也就是当请求流量突增的时候，上游流量的抖动可能会扩散到下游服务。

令牌桶是限制进入的速率，漏桶是限制出的速率。一般来说，如果下游服务没有非常严格的速率限制，选择令牌桶会更好，它在效率和抗抖动之间的横权更好一些

### 如何确定限流的阈值

- 通过压力测试来决定限流的阈值
- 根据经验设置一个比较保守，并且满足系统负载要求的阈值，在之后的使用中慢慢进行调整

**限流可能会引入脆弱性**

使用限流机制比较好的一个方式是，在系统的核心链路和核心服务上，默认启用限流机制，比如，像网关这样的流量入口和账号这样的核心服务，不论是限流阈值的设定，还是脆弱性的判断，我们都可以通过减少限流引入的范围，来简化使用限流的复杂度；而对于其他的位置和服务，则默认不启用限流机制，在出现故障的时候，通过手动设置阈值再启用，把它作为处理系统故障的一个手段。



### Nginx网关限流

Nginx 限流，主要是依赖 Nginx 自带的限流功能，针对请求的来源 IP 或者自定义的一个关键参数来做限流，比如用户 ID。其配置限流规则的语法为：

```
limit_req_zone <变量名> zone=<限流规则名称>:<内存大小> rate=<速率阈值>r/s;
```







## 降级-丢车保帅

在故障出现的时候，通过减少或停掉非核心业务，来降低系统的负载，让核心业务不会受到，或者少受到影响

降级机制能从全局角度对资源进行调配，通过牺牲非核心服务来保障核心服务的稳定性

降级一般是在网关层做

## 扩容

对于容器层面的扩容有两个维度，一个是水平扩容，即通过增加服务的实例数量对系统进行扩容；另一个是垂直扩容，即通过升级服务部署节点的资源对系统进行扩容





# Zookeeper

Zookeeper是一个开源的分布式协同服务系统

## 典型应用场景

适用于存储协同相关的关键数据，不适合用于大数据量存储

1. 配置管理
2. DNS服务
3. 组成员管理
4. 各种分布式锁



note.youdao.com/noteshare?id=df15b9a4c400815870b14a58c25dbb8f&sub=27F8AA04B3254C51A63932A208D6B224















# 搭建秒杀系统

围绕三个方面展开

- **高性能。** 秒杀涉及大量的并发读和并发写，因此支持高并发访问这点非常关键。设计从这4个方面展开：数据的动静分离方案、热点的发现与隔离、请求的削峰与分层过滤、服务端的极致优化。
- **一致性。** 在大并发更新的过程中秒杀中商品减库存都要保证数据的准确性，防止超卖问题
- **高可用。** 保证系统的高可用和正确性，我们还要设计一个PlanB来兜底，以便在最坏情况发生时仍然能够从容应对。



## 架构原则

- 数据要尽量少 	用户请求的数据能少就少、系统依赖的数据能少就少
- 请求数要尽量少      减少请求数最常用的一个实践就是合并CSS和JavaScript文件
- 路径要尽量短      “路径”，就是用户发出请求到返回数据这个过程中，需求经过的中间的节点数。将多个相互强依赖的应用合并部署在一起
- 依赖要尽量少      依赖，指的是要完成一次用户请求必须依赖的系统或者服务，这里的依赖指的是强依赖  
- 不要有单点          单点意味着没有备份，风险不可控



**架构优化**

1. 把秒杀系统独立出来单独打造一个系统，这样可以有针对性地做优化，例如这个独立出来的系统就减少了店铺装修的功能，减少了页面的复杂度；
2. 在系统部署上也独立做一个机器集群，这样秒杀的大流量就不会影响到正常的商品购买集群的机器负载；
3. 将热点数据（如库存数据）单独放到一个缓存系统中，以提高“读性能”；
4. 对页面进行彻底的动静分离，使得用户秒杀时不需要刷新整个页面，而只需要点击抢宝按钮，借此把页面刷新的数据降到最少；
5. 增加系统限流保护，防止最坏情况发生。
6. 增加秒杀答题，防止有秒杀器抢单。



## 动静分离

所谓“动静分离”，其实就是把用户请求的数据（如HTML页面）划分为“动态数据”和“静态数据”。

**“动态数据”和“静态数据”的主要区别就是看页面中输出的数据是否和URL、浏览者、时间、地域相关，以及是否含有Cookie等私密数据**。

**静态数据缓存到离用户最近的地方**。静态数据就是那些相对不会变化的数据，因此我们可以把它们缓存起来。常见的就三种，用户浏览器里、CDN上或者在服务端的Cache中。你应该根据情况，把它们尽量缓存到离用户最近的地方。



## 热点数据的发现与处理

**静态热点数据**，指能够提前预测的热点数据。例如，我们可以通过卖家报名的方式提前筛选出来，通过报名系统对这些热点商品进行打标。另外，我们还可以通过大数据分析来提前发现热点商品，比如我们分析历史成交记录、用户的购物车记录，来发现哪些商品可能更热门、更好卖，这些都是可以提前分析出来的热点。实时性较差

**动态热点数据**，就是不能被提前预测到的，系统在运行过程中临时产生的热点。例如，卖家在抖音上做了广告，然后商品一下就火了，导致它在短时间内被大量购买。

**动态热点发现系统的具体实现**。

1. 构建一个异步的系统，它可以收集交易链路上各个环节中的中间件产品的热点Key，如Nginx、缓存、RPC服务框架等这些中间件（一些中间件产品本身已经有热点统计模块）。
2. 建立一个热点上报和可以按照需求订阅的热点服务的下发规范，主要目的是通过交易链路上各个系统（包括详情、购物车、交易、优惠、库存、物流等）访问的时间差，把上游已经发现的热点透传给下游系统，提前做好保护。比如，对于大促高峰期，详情系统是最早知道的，在统一接入层上Nginx模块统计的热点URL。
3. 将上游系统收集的热点数据发送到热点服务台，然后下游系统（如交易系统）就会知道哪些商品会被频繁调用，然后做热点保护。





# MQ  

message queue，是在消息的传输过程中保存消息的容器。多用于分布式系统之间进行通信。

**优势**

应用解耦：提高系统容错性和可维护性

异步提速：提升用户体验和系统吞吐量

削峰填谷：提高系统稳定性



# kafka

依赖zookeeper，配置`zookeeper.connect=host:2181`









